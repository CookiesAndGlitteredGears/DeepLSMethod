{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xyPiwh8A3EVY"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def TicTocGenerator():\n",
        "    # Generator that returns time differences\n",
        "    ti = 0           # initial time\n",
        "    tf = time.time() # final time\n",
        "    while True:\n",
        "        ti = tf\n",
        "        tf = time.time()\n",
        "        yield tf-ti # returns the time difference\n",
        "\n",
        "TicToc = TicTocGenerator() # create an instance of the TicTocGen generator\n",
        "\n",
        "# This will be the main function through which we define both tic() and toc()\n",
        "def toc(tempBool=True):\n",
        "    # Prints the time difference yielded by generator instance TicToc\n",
        "    tempTimeInterval = next(TicToc)\n",
        "    if tempBool:\n",
        "        print( \"Elapsed time: %f seconds.\\n\" %tempTimeInterval )\n",
        "\n",
        "def tic():\n",
        "    # Records a time in TicToc, marks the beginning of a time interval\n",
        "    toc(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9hZDAflD3EVc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn import functional as F\n",
        "from torch import nn, optim\n",
        "from math import exp\n",
        "import os\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XfarxT613EVd"
      },
      "outputs": [],
      "source": [
        "# initialize parameters\n",
        "#dx is the step size for test set\n",
        "torch.manual_seed(0)\n",
        "today = datetime.datetime.today()\n",
        "d4 = today.strftime(\"%b-%d-%Y\")\n",
        "\n",
        "global k, dx, beta\n",
        "k, dx, beta = 10, .001, 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "APCNELBk3EVe"
      },
      "outputs": [],
      "source": [
        "def f(x):\n",
        "    if x< 0.5 :\n",
        "        return 8*k*(3*x-1)\n",
        "    else :\n",
        "        return 4*k*(k+1)\n",
        "\n",
        "def g(x):\n",
        "    return torch.tensor([0.], requires_grad=True)\n",
        "\n",
        "def u_exact(x):\n",
        "    if x< 0.5 :\n",
        "        return 4*k*x**2*(1-x)\n",
        "    else :\n",
        "        return (2*(k+1)*x-1)*(1-x)\n",
        "\n",
        "def sigma_exact(x):\n",
        "    if x< 0.5 :\n",
        "        return 12*k*x**2-8*k*x\n",
        "    else :\n",
        "        return 4*k*(k+1)*x - 2 *k*k - 3*k\n",
        "\n",
        "sq = lambda x: x ** 2\n",
        "vsq = np.vectorize(sq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArziQL9k3EVf",
        "outputId": "0df3e3d4-b303-47cd-c671-e5ef21215ce3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "u: H1 norm square: 70076.634481, L2 norm square: 10.414888 \n",
            "sigma: H1 norm square: 1038805.849400, L2 norm square: 7051.299400 \n"
          ]
        }
      ],
      "source": [
        "# compute H1 norm of true u and sigma\n",
        "L = 0.\n",
        "R = 1.\n",
        "test_set1 =  np.arange(L, R/2, dx)\n",
        "test_set2 =  np.arange(R/2, R, dx)\n",
        "test_set = np.concatenate((test_set1, test_set2))\n",
        "u1 = np.vectorize(u_exact)(test_set1)\n",
        "ud1 = -np.vectorize(sigma_exact)(test_set1)\n",
        "u2 = np.vectorize(u_exact)(test_set2)\n",
        "ud2 = -np.vectorize(sigma_exact)(test_set2)\n",
        "u_h1 = np.sum(dx*(vsq(u1) + vsq(ud1)+ k* vsq(u2) + k * vsq(ud2) ))\n",
        "u_l2 = np.sum(dx*vsq(u1)+ dx*vsq(u2) )\n",
        "\n",
        "sigma1 = np.vectorize(sigma_exact)(test_set1)\n",
        "sigmad1 = np.vectorize(f)(test_set1)\n",
        "sigma2 = np.vectorize(sigma_exact)(test_set2)\n",
        "sigmad2 = np.vectorize(f)(test_set2)\n",
        "\n",
        "sigma_h1 = np.sum(dx*(vsq(sigma1) + vsq(sigmad1) + k* vsq(sigma2) + k* vsq(sigmad2)))\n",
        "sigma_l2 = np.sum(dx*vsq(sigma1) + dx*vsq(sigma2) )\n",
        "\n",
        "print('u: H1 norm square: %.6f, L2 norm square: %.6f ' %(u_h1, u_l2))\n",
        "print('sigma: H1 norm square: %.6f, L2 norm square: %.6f ' %(sigma_h1, sigma_l2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "c486Cek03EVg"
      },
      "outputs": [],
      "source": [
        "class MuSigmaPde(nn.Module):\n",
        "    def __init__(self, dimension, mesh = 32, neuron = 24):\n",
        "        super(MuSigmaPde, self).__init__()\n",
        "\n",
        "        self.xdim = dimension\n",
        "        # Layer 1\n",
        "        self.fc1mu = nn.Linear(dimension, mesh)\n",
        "        self.fc1sig = nn.Linear(dimension, mesh)\n",
        "        # Layer 2\n",
        "        self.fc2mu = nn.Linear(mesh, neuron)\n",
        "        self.fc2sig = nn.Linear(mesh, neuron)\n",
        "        # Layer 3\n",
        "        self.fc3mu = nn.Linear(neuron, neuron)\n",
        "        self.fc3sig = nn.Linear(neuron, neuron)\n",
        "        # Layer 4\n",
        "        self.fc4mu = nn.Linear(neuron, 1)\n",
        "        self.fc4sig = nn.Linear(neuron, dimension)\n",
        "\n",
        "    def forward(self, x):   #Activation Function Sigmoid\n",
        "        assert(len(x.shape) == 1 and x.shape[0] == self.xdim)\n",
        "        mu =  torch.sigmoid(self.fc2mu(torch.sigmoid(self.fc1mu(x))))\n",
        "        sig =  torch.sigmoid(self.fc2sig(torch.sigmoid(self.fc1sig(x))))\n",
        "        mu =  self.fc4mu(torch.sigmoid(self.fc3mu(mu)))\n",
        "        sig = self.fc4sig(torch.sigmoid(self.fc3sig(sig)))\n",
        "        return mu, sig\n",
        "\n",
        "    def net_grad(self, x, h):\n",
        "        mu_center, sigma_center = self.forward(x)\n",
        "        mu_forward, sigma_forward = self.forward(x - 0.5*h)\n",
        "\n",
        "        mu_grad_forward = (mu_center - mu_forward)/(0.5*h)\n",
        "        sigma_grad_forward = (sigma_center - sigma_forward)/(0.5*h)\n",
        "\n",
        "        return mu_grad_forward, sigma_grad_forward\n",
        "\n",
        "    def loss_function_bulk(self, x,h):    #FOSLS\n",
        "        mu, sigma = self.forward(x)\n",
        "        mu_grad, sigma_grad = self.net_grad(x,h)\n",
        "        if x< 0.5:\n",
        "            LSE = torch.sum((mu_grad + sigma)**2) + (sigma_grad - f(x))**2\n",
        "        else:\n",
        "            LSE = torch.sum((mu_grad * k**(0.5) + sigma* k**(-0.5))**2) + (sigma_grad - f(x))**2\n",
        "        return LSE\n",
        "\n",
        "    def loss_function_surf(self, x):\n",
        "        mu, sigma = self.forward(x)\n",
        "        # Boundary condition penalty\n",
        "        BCP = beta * (mu - g(x))**2\n",
        "        return BCP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6tPM8LDR3EVk"
      },
      "outputs": [],
      "source": [
        "layerArray = [1,32,24,24,1]\n",
        "\n",
        "model = MuSigmaPde(dimension =1, mesh = 32, neuron = 24)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKzEkY2B3EVm",
        "outputId": "c48717ad-e0cb-468d-fee1-54b9807a908b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2962"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "sum([p.numel() for p in model.parameters()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxCh_j_b3EVn",
        "outputId": "628d6f05-f5dd-4462-f19d-3d5feac23d79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bulk points number 500 \n",
            "surface points number 2\n",
            "test points number 1000\n",
            "dx for difference in testing 0.001\n",
            "trainging iteration 1\n"
          ]
        }
      ],
      "source": [
        "h = .002\n",
        "L, R = 0., 1.\n",
        "epochs = 1\n",
        "bulk_set, surf_set =  np.arange(L, R, h), [L, R]\n",
        "loss_bulk_record, loss_surf_record = [], []\n",
        "print('bulk points number %d \\nsurface points number %d\\ntest points number %d\\ndx for difference in testing %.3g\\ntrainging iteration %d' %(np.size(bulk_set), np.size(surf_set), np.size(test_set), dx, epochs))\n",
        "\n",
        "folder = f'{d4} fosls sigmoid/{layerArray}/{int(1/h)}_base'\n",
        "if not os.path.exists(folder): os.makedirs(folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJRLrTOQ3EVq"
      },
      "outputs": [],
      "source": [
        "def exp_lr_scheduler(optimizer, epoch, lr_decay=0.1, lr_decay_epoch=10000):\n",
        "    \"\"\"Decay learning rate by a factor of lr_decay every lr_decay_epoch epochs\"\"\"\n",
        "    if epoch % lr_decay_epoch:\n",
        "        return optimizer\n",
        "    if epoch == 0:\n",
        "        return optimizer\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] *= lr_decay\n",
        "    return optimizer\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_S2uHkLj3EVr"
      },
      "outputs": [],
      "source": [
        "tic()\n",
        "local_min = 792\n",
        "for j in range(epochs):\n",
        "    loss_bulk = torch.zeros(1)\n",
        "    loss_surf = torch.zeros(1)\n",
        "\n",
        "    for point in bulk_set:\n",
        "        x = torch.tensor([point+ 0.5*h])\n",
        "        loss_bulk += h*model.loss_function_bulk(x,h)\n",
        "\n",
        "    for point in surf_set:\n",
        "        x = torch.tensor([point])\n",
        "        loss_surf += model.loss_function_surf(x)\n",
        "\n",
        "    loss_bulk_record.append(loss_bulk.data[0])\n",
        "    loss_surf_record.append(loss_surf.data[0])\n",
        "\n",
        "    loss = loss_bulk + loss_surf\n",
        "    print('Train Epoch: {}, Loss: {:.6f}, loss bulk: {:.6f}, loss surf: {:.6f}'.format(j, loss.item(), loss_bulk.item(), loss_surf.item()))\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    exp_lr_scheduler(optimizer, j)\n",
        "\n",
        "    if loss.item() < local_min:\n",
        "        print('updating the parameters')\n",
        "        local_min = loss.item()\n",
        "        torch.save(model.state_dict(),'./diff_sigmoid')\n",
        "\n",
        "    optimizer.step()\n",
        "toc()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HO1QBPgI3EVs"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('./diff_sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GXq0toj3EVt"
      },
      "outputs": [],
      "source": [
        "mu_err_h1 = torch.zeros(1)\n",
        "sigma_err_h1 = torch.zeros(1)\n",
        "bdd_err = torch.zeros(1)\n",
        "mu_err_l2 = torch.zeros(1)\n",
        "sigma_err_l2 = torch.zeros(1)\n",
        "G_relative = torch.zeros(1)\n",
        "mu_err_semi = torch.zeros(1)\n",
        "\n",
        "for point in test_set:\n",
        "\n",
        "    x = torch.tensor([point+ 0.5*dx])\n",
        "    mu, sigma = model(x)\n",
        "    mu_grad, sigma_grad = model.net_grad(x,dx)\n",
        "\n",
        "    # esitmate H1 norm error\n",
        "    mu_diff = (mu - u_exact(x))**2  + (mu_grad + sigma_exact(x))**2\n",
        "\n",
        "    if x.item() < 0.5:\n",
        "        mu_diff_simi = (mu_grad + sigma_exact(x))**2\n",
        "    else:\n",
        "        mu_diff_simi = (mu_grad + sigma_exact(x)/k)**2\n",
        "\n",
        "    sigma_diff = (sigma - sigma_exact(x))**2 + (sigma_grad - f(x))**2\n",
        "\n",
        "    mu_err_h1 += dx*mu_diff\n",
        "    sigma_err_h1 += dx*sigma_diff\n",
        "\n",
        "    # estimate L2 norm error\n",
        "    mu_err_l2 += dx*(mu - u_exact(x))**2\n",
        "    sigma_err_l2 += dx*(sigma - sigma_exact(x))**2\n",
        "\n",
        "    # estimate H1 semi norm  error\n",
        "    mu_err_semi += dx*mu_diff_simi\n",
        "    sigma_err_semi = sigma_err_h1 - sigma_err_l2\n",
        "\n",
        "H1_err = mu_err_h1 + sigma_err_h1\n",
        "H1_err_relative = ((H1_err)**(1/2)) / ((u_h1 + sigma_h1)**(1/2))\n",
        "L2_err = mu_err_l2 + sigma_err_l2\n",
        "L2_err_relative = ((L2_err)**(1/2)) / ((u_l2 + sigma_l2)**(1/2))\n",
        "mu_err_h1_relative = (mu_err_h1/u_h1)**(1/2)\n",
        "mu_err_l2_relative = (mu_err_l2/u_l2)**(1/2)\n",
        "mu_err_semi_relative = (mu_err_semi/(sigma_l2))**(1/2)\n",
        "sigma_err_h1_relative = (sigma_err_h1/sigma_h1)**(1/2)\n",
        "sigma_err_l2_relative = (sigma_err_l2/sigma_l2)**(1/2)\n",
        "sigma_err_semi_relative = (sigma_err_semi/(sigma_h1 - sigma_l2))**(1/2)\n",
        "bdd_err += abs(mu - g(x))\n",
        "\n",
        "G_rel = (local_min)**(1/2)/((u_h1 + sigma_h1)**(1/2))\n",
        "\n",
        "print('u: L2_rel: {:.6f}, H1_semi_rel: {:.6f}'.format( mu_err_l2_relative.item(), mu_err_semi_relative.item()))\n",
        "print('sigma: L2_rel: {:.6f}\\n'.format(sigma_err_l2_relative.item()))\n",
        "print('G_rel: {:.6f}\\n'.format(G_rel.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gJ0Q3ay3EVt"
      },
      "outputs": [],
      "source": [
        "points = test_set\n",
        "yt = np.zeros_like(points)\n",
        "y_diff = np.zeros_like(points)\n",
        "ymu = np.zeros_like(points)\n",
        "ysig = np.zeros_like(points)\n",
        "for i in range(len(points)):\n",
        "    yt[i] = u_exact(points[i])\n",
        "    y_diff[i] =  sigma_exact(points[i])\n",
        "    ymu[i], ysig[i] = model(torch.tensor([points[i]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyFV0aWG3EVu"
      },
      "outputs": [],
      "source": [
        "plt.plot(points, yt, color = 'b', label = 'u_true')\n",
        "plt.plot(points, ymu, color = 'r', label = 'u_approximation')\n",
        "plt.legend()\n",
        "plt.savefig(f'{folder}/u_plot_p_{problem_number}_mesh_{int(1/h)}')\n",
        "plt.clf()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tn-y_gyV3EVu"
      },
      "outputs": [],
      "source": [
        "plt.plot(points, y_diff, color = 'b', label = 'sigma_true')\n",
        "plt.plot(points, ysig, color = 'r', label = 'sigma_approximation')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "52SDhEG-3EVv"
      },
      "outputs": [],
      "source": [
        "num = np.arange(1, len(loss_bulk_record)+1, 1)\n",
        "plt.plot(num, loss_bulk_record)\n",
        "plt.plot(num, loss_surf_record)\n",
        "plt.plot(num, np.add(loss_bulk_record , loss_surf_record))\n",
        "plt.savefig(f'{folder}/loss_plot_p_{problem_number}_mesh_{int(1/h)}')\n",
        "plt.clf()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DRAZpGk43EVw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "sxFLFOvG3EVw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}