{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gg-sRLVjtU3p"
   },
   "source": [
    "Consider the following equation\n",
    "$$-\\varepsilon^2 \\Delta u + u = f, \\quad x\\in \\Omega$$\n",
    "$$u = 0, \\quad x \\in \\partial \\Omega.$$\n",
    "We choose the true solution $u = \\tanh(\\frac{1}{\\varepsilon}(x^2 - \\frac{1}{4})) - \\tanh(\\frac{3}{4\\varepsilon})$ on the interval $\\Omega = [-1,1]$.\n",
    "\n",
    "By FOSLS method, we have \n",
    "$$\\sigma = - \\varepsilon^2 \\nabla u.$$\n",
    "And the loss function\n",
    "$$G(\\sigma, u; f) = \\|\\text{div }\\sigma + u -f \\|_{0,\\Omega}^2 + \\|\\frac{1}{\\varepsilon}\\sigma + \\varepsilon \\nabla u\\|_{0,\\Omega}^2 + \\beta \\|u\\|^2_{0,\\Omega}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def TicTocGenerator():\n",
    "    # Generator that returns time differences\n",
    "    ti = 0           # initial time\n",
    "    tf = time.time() # final time\n",
    "    while True:\n",
    "        ti = tf\n",
    "        tf = time.time()\n",
    "        yield tf-ti # returns the time difference\n",
    "\n",
    "TicToc = TicTocGenerator() # create an instance of the TicTocGen generator\n",
    "\n",
    "# This will be the main function through which we define both tic() and toc()\n",
    "def toc(tempBool=True):\n",
    "    # Prints the time difference yielded by generator instance TicToc\n",
    "    tempTimeInterval = next(TicToc)\n",
    "    if tempBool:\n",
    "        print( \"Elapsed time: %f seconds.\\n\" %tempTimeInterval )\n",
    "\n",
    "def tic():\n",
    "    # Records a time in TicToc, marks the beginning of a time interval\n",
    "    toc(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "MSD0tkusziSh"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "from torch import nn, optim\n",
    "from math import cosh\n",
    "from math import tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "YGNnNFNN4WIZ"
   },
   "outputs": [],
   "source": [
    "global eps, dx, beta\n",
    "eps, dx, beta = 0.01, .001, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "voyw6KWq4hEh"
   },
   "outputs": [],
   "source": [
    "def u_exact(x):\n",
    "    y = (1/eps) * (x**2-1/4)\n",
    "    return tanh(y) - tanh(3/(4*eps))\n",
    "\n",
    "def sigma_exact(x):\n",
    "    y = (1/eps) * (x**2 - 1/4)\n",
    "    return  -(2*eps*x)/(cosh(y)**2)  \n",
    "  \n",
    "def f(x):\n",
    "    y = (1/eps) * (x**2 - 1/4)\n",
    "    return -2*(eps-4*x**2*tanh(y))*(1/cosh(y))**2 + u_exact(x)\n",
    "  \n",
    "def g(x):\n",
    "    return torch.tensor([0.], requires_grad=True)\n",
    "\n",
    "sq = lambda x: x ** 2\n",
    "vsq = np.vectorize(sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "sz6b4MVM0O35",
    "outputId": "0d76752d-3164-4f9c-f10f-422253627436"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u: H1 norm square: 3.985986, L2 norm square: 3.959321 \n",
      "sigma: H1 norm square: 0.048009, L2 norm square: 0.000003 \n",
      "sigma: L2 norm square: 0.000003 \n"
     ]
    }
   ],
   "source": [
    "# compute H1 norm of true u and sigma\n",
    "L = -1.\n",
    "R = 1.\n",
    "test_set =  np.arange(L, R+dx, dx)\n",
    "u = np.vectorize(u_exact)(test_set)\n",
    "ud = -np.vectorize(sigma_exact)(test_set)/(eps*eps) \n",
    "u_h1 = np.sum(dx*(vsq(u) + eps*eps*vsq(ud)))\n",
    "u_l2 = np.sum(dx*vsq(u))\n",
    "\n",
    "sigma = np.vectorize(sigma_exact)(test_set)\n",
    "sigmad = np.vectorize(f)(test_set) - u        \n",
    "sigma_h1 = np.sum(dx*(vsq(sigma)/(eps*eps) + vsq(sigmad)))\n",
    "sigma_l2 = np.sum(dx*vsq(sigma))\n",
    "\n",
    "print('u: H1 norm square: %.6f, L2 norm square: %.6f ' %(u_h1, u_l2))\n",
    "print('sigma: H1 norm square: %.6f, L2 norm square: %.6f ' %(sigma_h1, sigma_l2))\n",
    "print('sigma: L2 norm square: %.6f ' %(sigma_l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "x4-_eN6O17-u"
   },
   "outputs": [],
   "source": [
    "class MuSigmaPde(nn.Module):\n",
    "    def __init__(self, dimension, mesh = 32, neuron = 24):\n",
    "        super(MuSigmaPde, self).__init__()\n",
    "\n",
    "        self.xdim = dimension\n",
    "        # Layer 1\n",
    "        self.fc1mu = nn.Linear(dimension, mesh)\n",
    "        self.fc1sig = nn.Linear(dimension, mesh)\n",
    "        # Layer 2\n",
    "        self.fc2mu = nn.Linear(mesh, neuron)\n",
    "        self.fc2sig = nn.Linear(mesh, neuron)\n",
    "        # Layer 3\n",
    "        self.fc3mu = nn.Linear(neuron, neuron)\n",
    "        self.fc3sig = nn.Linear(neuron, neuron)\n",
    "        # Layer 4\n",
    "        self.fc4mu = nn.Linear(neuron, 1)\n",
    "        self.fc4sig = nn.Linear(neuron, dimension)\n",
    "\n",
    "    def forward(self, x):   #Activation Function (Sigmoid)\n",
    "        assert(len(x.shape) == 1 and x.shape[0] == self.xdim)\n",
    "        y_mu =  torch.sigmoid(self.fc2mu(torch.sigmoid(self.fc1mu(x))))\n",
    "        y_sig =  torch.sigmoid(self.fc2sig(torch.sigmoid(self.fc1sig(x))))\n",
    "        mu =  self.fc4mu(torch.sigmoid(self.fc3mu(y_mu)))\n",
    "        sigma = self.fc4sig(torch.sigmoid(self.fc3sig(y_sig)))\n",
    "        return mu, sigma\n",
    "      \n",
    "    def net_grad(self, x):\n",
    "        mu_center, sigma_center = self.forward(x)\n",
    "        mu_forward, sigma_forward = self.forward(x - .5*dx)\n",
    "\n",
    "        mu_grad_forward = (mu_center - mu_forward)/(.5*dx)\n",
    "        sigma_grad_forward = (sigma_center - sigma_forward)/(.5*dx)\n",
    "        return mu_grad_forward, sigma_grad_forward\n",
    "    \n",
    "    def loss_function_bulk(self, x):\n",
    "        mu, sigma = self.forward(x)\n",
    "        mu_grad, sigma_grad = self.net_grad(x) \n",
    "        LSE = 0.5*eps*eps*(mu_grad)**2 + 0.5*mu*mu -f(x)*mu   #Energy\n",
    "        return LSE \n",
    "\n",
    "    def loss_function_surf(self, x):\n",
    "        mu, sigma = self.forward(x)\n",
    "        # Boundary condition penalty\n",
    "        BCP = beta * (mu - g(x))**2\n",
    "        return BCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "dDMxN-_y2St1"
   },
   "outputs": [],
   "source": [
    "model = MuSigmaPde(dimension =1, mesh = 32, neuron = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ls5bmq7e2V2r",
    "outputId": "442a4dcb-5edb-48e5-8759-30df73fc8892"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2962"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "pXXG34cf2WnP",
    "outputId": "160e8b34-1505-4f29-c78c-54184c81589f"
   },
   "outputs": [],
   "source": [
    "#h determines the size of quadrature points\n",
    "\n",
    "h = .001\n",
    "epochs = 20000\n",
    "L, R = -1., 1.\n",
    "bulk_set, surf_set =  np.arange(L, R, h), [L, R]\n",
    "loss_bulk_record, loss_surf_record = [], []\n",
    "print('bulk points number %d \\nsurface points number %d\\ntest points number %d\\ndx for difference in testing %.3g\\ntrainging iteration %d' %(np.size(bulk_set), np.size(surf_set), np.size(test_set), dx, epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "0xVACUNZ2gMz"
   },
   "outputs": [],
   "source": [
    "def exp_lr_scheduler(optimizer, epoch, lr_decay=0.5, lr_decay_epoch=5000):\n",
    "    \"\"\"Decay learning rate by a factor of lr_decay every lr_decay_epoch epochs\"\"\"\n",
    "    if epoch % lr_decay_epoch:\n",
    "        return optimizer\n",
    "    if epoch == 0:\n",
    "        return optimizer\n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] *= lr_decay\n",
    "    return optimizer\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic()\n",
    "local_min = 0.05\n",
    "for j in range(epochs):\n",
    "    loss_bulk = torch.zeros(1)\n",
    "    loss_surf = torch.zeros(1)\n",
    "\n",
    "    for point in bulk_set:\n",
    "        x = torch.tensor([point+ 0.5*dx])\n",
    "        loss_bulk += h*model.loss_function_bulk(x)\n",
    "               \n",
    "    for point in surf_set:\n",
    "        x = torch.tensor([point])\n",
    "        loss_surf += model.loss_function_surf(x)\n",
    "\n",
    "    # record each loss\n",
    "    loss_bulk_record.append(loss_bulk.data[0])\n",
    "    loss_surf_record.append(loss_surf.data[0])\n",
    "       \n",
    "    loss = loss_bulk + loss_surf\n",
    "    print('Train Epoch: {}, Loss: {:.6f}, loss bulk: {:.6f}, loss surf: {:.6f}'.format(j, loss.item(), loss_bulk.item(), loss_surf.item()))\n",
    "    optimizer.zero_grad()\n",
    "    #exp_lr_scheduler(optimizer, j)\n",
    "    if loss.item() < local_min:\n",
    "        print('updating the parameters')\n",
    "        local_min = loss.item()\n",
    "        torch.save(model.state_dict(),'./singular_sigmoid_energy')\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "toc()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 59307
    },
    "colab_type": "code",
    "id": "rbfW9b6U2iL2",
    "outputId": "6d8a7588-8ae8-4c4c-f8fe-28296185b1fc"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./singular_sigmoid_energy'))\n",
    "mu_err_h1 = torch.zeros(1)\n",
    "sigma_err_h1 = torch.zeros(1)\n",
    "bdd_err = torch.zeros(1)\n",
    "mu_err_l2 = torch.zeros(1)\n",
    "sigma_err_l2 = torch.zeros(1)\n",
    "mu_err_semi = torch.zeros(1)\n",
    "    \n",
    "test_set =  np.arange(L, R+dx, dx)\n",
    "\n",
    "for point in test_set:\n",
    "\n",
    "    x = torch.tensor([point+ 0.5*dx])\n",
    "    mu, sigma = model(x)\n",
    "    mu_grad, sigma_grad = model.net_grad(x)\n",
    "\n",
    "    # esitmate H1 norm error\n",
    "    mu_diff = (mu_grad + (1/eps)**2 * sigma_exact(x))**2\n",
    "    sigma_diff = (sigma - sigma_exact(x))**2 + (sigma_grad - f(x) + u_exact(x))**2\n",
    "    mu_err_h1 += dx*mu_diff\n",
    "    sigma_err_h1 += dx*sigma_diff\n",
    "\n",
    "    # estimate L2 norm error\n",
    "    mu_err_l2 += dx*(mu - u_exact(x))**2\n",
    "    sigma_err_l2 += dx*(sigma - sigma_exact(x))**2\n",
    "    \n",
    "    # estimate H1 semi norm  error\n",
    "    mu_err_semi += dx*(mu - u_exact(x))**2 + dx*eps*eps*((mu_grad + (1/eps)**2 * sigma_exact(x))**2)\n",
    "\n",
    "mu_err_l2_relative = (mu_err_l2/u_l2)**(1/2)\n",
    "mu_err_semi_relative = (mu_err_semi/u_h1)**(1/2)\n",
    "sigma_err_l2_relative = (sigma_err_l2/sigma_l2)**(1/2)\n",
    "G_rel = local_min**(1/2)/((u_h1 + sigma_h1)**(1/2))\n",
    "\n",
    "print('u: L2_rel: {:.6f}, H1_semi_rel: {:.6f}'.format( mu_err_l2_relative.item(), mu_err_semi_relative.item()))\n",
    "print('sigma: L2_rel: {:.6f}\\n'.format(sigma_err_l2_relative.item()))\n",
    "print('G_rel: {:.6f}\\n'.format(G_rel.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OGFERRpr3bWV"
   },
   "outputs": [],
   "source": [
    "points = test_set\n",
    "yt = np.vectorize(u_exact)(points)\n",
    "y_diff = np.vectorize(sigma_exact)(points)\n",
    "ymu = np.zeros_like(points)\n",
    "ysig = np.zeros_like(points)\n",
    "for i in range(len(points)):\n",
    "    ymu[i], ysig[i] = model(torch.tensor([points[i]]))\n",
    "for param_group in optimizer.param_groups:\n",
    "    print(param_group['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kfjpdjrf3fhT"
   },
   "outputs": [],
   "source": [
    "plt.plot(points, yt, color = 'b', label = 'u_true')\n",
    "plt.plot(points, ymu, color = 'r', label = 'u_approximation')\n",
    "plt.legend()           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z1GCc6j23hKp"
   },
   "outputs": [],
   "source": [
    "plt.plot(points, y_diff, color = 'b', label = 'sigma_true')\n",
    "plt.plot(points, ysig, color = 'r', label = 'sigma_approximation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EiXq0kWe7f0e"
   },
   "outputs": [],
   "source": [
    "num = np.arange(1, len(loss_bulk_record)+1, 1)\n",
    "plt.plot(num, loss_bulk_record)\n",
    "plt.plot(num, loss_surf_record)\n",
    "plt.plot(num, np.add(loss_bulk_record , loss_surf_record))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Num2 FOSLS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
