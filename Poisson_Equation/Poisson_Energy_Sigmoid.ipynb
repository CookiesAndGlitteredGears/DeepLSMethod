{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zUqGYU0Fg6ik"
   },
   "source": [
    "Consider the following equation\n",
    "$$- u''  = f, \\quad x\\in \\Omega$$\n",
    "$$u = 0, \\quad x \\in \\partial \\Omega.$$\n",
    "We choose the true solution $u = x(e^{-(x-\\frac{1}{3})^2/K} - e^{-\\frac{4}{9}/K})$ with $K = 0.01$ on the interval $\\Omega = [-1,1]$.\n",
    "\n",
    "By FOSLS method, we have \n",
    "$$\\sigma = - u'.$$\n",
    "And the loss function\n",
    "$$G(\\sigma, u; f) = \\|\\text{div }\\sigma + u -f \\|_{0,\\Omega}^2 + \\|\\frac{1}{\\varepsilon}\\sigma + \\varepsilon \\nabla u\\|_{0,\\Omega}^2 + \\beta \\|u\\|^2_{0,\\Omega}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zhjCXFpXg6in"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def TicTocGenerator():\n",
    "    # Generator that returns time differences\n",
    "    ti = 0           # initial time\n",
    "    tf = time.time() # final time\n",
    "    while True:\n",
    "        ti = tf\n",
    "        tf = time.time()\n",
    "        yield tf-ti # returns the time difference\n",
    "\n",
    "TicToc = TicTocGenerator() # create an instance of the TicTocGen generator\n",
    "\n",
    "# This will be the main function through which we define both tic() and toc()\n",
    "def toc(tempBool=True):\n",
    "    # Prints the time difference yielded by generator instance TicToc\n",
    "    tempTimeInterval = next(TicToc)\n",
    "    if tempBool:\n",
    "        print( \"Elapsed time: %f seconds.\\n\" %tempTimeInterval )\n",
    "\n",
    "def tic():\n",
    "    # Records a time in TicToc, marks the beginning of a time interval\n",
    "    toc(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qaI185uEg6iy"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "from torch import nn, optim\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "SAM9clGUg6i5"
   },
   "outputs": [],
   "source": [
    "# initialize parameters\n",
    "global k, dx, beta \n",
    "k, dx, beta = .01, .005, 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "EC-nFcF6g6jA"
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return -(2*exp(-(x - 1/3)**2/k)*(6*k + 2*x - 27*k*x - 12*x**2 + 18*x**3))/(9*k**2)\n",
    "  \n",
    "def g(x):\n",
    "    return torch.tensor([0.], requires_grad=True)\n",
    "\n",
    "def u_exact(x):\n",
    "    return x*(exp(-1/k*(x-1/3)**2) - exp(-4/(9*k)))\n",
    "\n",
    "def sigma_exact(x):\n",
    "    return exp(-4/(9*k)) - exp(-(x - 1/3)**2/k) + (x*exp(-(x - 1/3)**2/k)*(2*x - 2/3))/k\n",
    "  \n",
    "sq = lambda x: x ** 2\n",
    "vsq = np.vectorize(sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "e3y4nuk_g6jF",
    "outputId": "2de1fa7c-8266-4cfe-c48b-3d3b45b1416b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u: H1 norm square: 1.500809, L2 norm square: 0.014239 \n",
      "sigma: H1 norm square: 466.257229, L2 norm square: 1.486570 \n"
     ]
    }
   ],
   "source": [
    "# compute H1 norm of true u and sigma\n",
    "L = 0.\n",
    "R = 1.\n",
    "test_set =  np.arange(L, R+dx, dx)\n",
    "u = np.vectorize(u_exact)(test_set)\n",
    "ud = -np.vectorize(sigma_exact)(test_set)\n",
    "u_h1 = np.sum(dx*(vsq(u) + vsq(ud)))\n",
    "u_l2 = np.sum(dx*vsq(u))\n",
    "\n",
    "sigma = np.vectorize(sigma_exact)(test_set)\n",
    "sigmad = np.vectorize(f)(test_set)\n",
    "sigma_h1 = np.sum(dx*(vsq(sigma) + vsq(sigmad)))\n",
    "sigma_l2 = np.sum(dx*vsq(sigma))\n",
    "\n",
    "print('u: H1 norm square: %.6f, L2 norm square: %.6f ' %(u_h1, u_l2))\n",
    "print('sigma: H1 norm square: %.6f, L2 norm square: %.6f ' %(sigma_h1, sigma_l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "l4g2Q5NTg6jN"
   },
   "outputs": [],
   "source": [
    "class MuSigmaPde(nn.Module):\n",
    "    def __init__(self, dimension, mesh = 24, neuron = 14):\n",
    "        super(MuSigmaPde, self).__init__()\n",
    "\n",
    "        self.xdim = dimension\n",
    "        # Layer 1\n",
    "        self.fc1mu = nn.Linear(dimension, mesh)\n",
    "        self.fc1sig = nn.Linear(dimension, mesh)\n",
    "        # Layer 2\n",
    "        self.fc2mu = nn.Linear(mesh, neuron)\n",
    "        self.fc2sig = nn.Linear(mesh, neuron)\n",
    "        # Layer 3\n",
    "        self.fc3mu = nn.Linear(neuron, neuron)\n",
    "        self.fc3sig = nn.Linear(neuron, neuron)\n",
    "        # Layer 4\n",
    "        self.fc4mu = nn.Linear(neuron, 1)\n",
    "        self.fc4sig = nn.Linear(neuron, dimension)\n",
    "\n",
    "    def forward(self, x):  #Sigmoid activation function\n",
    "        assert(len(x.shape) == 1 and x.shape[0] == self.xdim)\n",
    "        y_mu =  torch.sigmoid(self.fc2mu(torch.sigmoid(self.fc1mu(x))))\n",
    "        y_sig =  torch.sigmoid(self.fc2sig(torch.sigmoid(self.fc1sig(x))))\n",
    "        mu =  self.fc4mu(torch.sigmoid(self.fc3mu(y_mu)))\n",
    "        sigma = self.fc4sig(torch.sigmoid(self.fc3mu(y_sig)) )\n",
    "        return mu, sigma\n",
    "      \n",
    "    def net_grad(self, x):\n",
    "        mu_center, sigma_center = self.forward(x)\n",
    "        mu_forward, sigma_forward = self.forward(x - .5*dx)\n",
    "\n",
    "        mu_grad_forward = (mu_center - mu_forward)/(.5*dx)\n",
    "        sigma_grad_forward = (sigma_center - sigma_forward)/(.5*dx)\n",
    "    \n",
    "        return mu_grad_forward, sigma_grad_forward\n",
    "    \n",
    "    def loss_function_bulk(self, x):   #energy functional\n",
    "        mu, sigma = self.forward(x)\n",
    "        mu_grad, sigma_grad = self.net_grad(x)\n",
    "        LSE = 0.5*(mu_grad)**2-f(x)*mu\n",
    "        return LSE\n",
    "\n",
    "    def loss_function_surf(self, x):\n",
    "        mu, sigma = self.forward(x)\n",
    "        # Boundary condition penalty\n",
    "        BCP = beta * (mu - g(x))**2\n",
    "        return BCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "7petcKsfg6jU"
   },
   "outputs": [],
   "source": [
    "model = MuSigmaPde(dimension =1, mesh = 24, neuron = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Sh-_Il9Og6ja",
    "outputId": "a2b34230-628a-4e8d-92f6-d7abae5c2907"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1246"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "rYz0L4s6g6jd",
    "outputId": "c6eec1a5-2868-4d8b-dbd9-7d0b62f15a50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk points number 200 \n",
      "surface points number 2\n",
      "test points number 201\n",
      "dx for difference 0.005\n",
      "trainging iteration 2000\n"
     ]
    }
   ],
   "source": [
    "# change h for different number of quadrature points. There are 1/h=200 quadrature points in this case.\n",
    "\n",
    "h = .005\n",
    "epochs = 10000\n",
    "L, R = 0., 1.\n",
    "bulk_set, surf_set =  np.arange(L, R, h), [L, R]\n",
    "loss_bulk_record, loss_surf_record = [], []\n",
    "print('bulk points number %d \\nsurface points number %d\\ntest points number %d\\ndx for difference in testing %.3g\\ntrainging iteration %d' %(np.size(bulk_set), np.size(surf_set), np.size(test_set), dx, epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "RFHN09wjg6jh"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "x66ogatig6jl",
    "outputId": "05bf55a1-7412-44d5-9545-f896a8c18f03"
   },
   "outputs": [],
   "source": [
    "tic()\n",
    "local_min = 100.0\n",
    "for j in range(epochs):\n",
    "    loss_bulk = torch.zeros(1)\n",
    "    loss_surf = torch.zeros(1)\n",
    "\n",
    "    for point in bulk_set:\n",
    "        x = torch.tensor([point+ 0.5*h])\n",
    "        loss_bulk += h*model.loss_function_bulk(x)\n",
    "               \n",
    "    for point in surf_set:\n",
    "        x = torch.tensor([point])\n",
    "        loss_surf += model.loss_function_surf(x)\n",
    "\n",
    "    # record each loss\n",
    "    loss_bulk_record.append(loss_bulk.data[0])\n",
    "    loss_surf_record.append(loss_surf.data[0])\n",
    "    \n",
    "\n",
    "    \n",
    "    loss = loss_bulk + loss_surf\n",
    "    if loss.item() < local_min:\n",
    "        local_min = loss.item()\n",
    "        torch.save(model.state_dict(),'./poisson_equationenergy_24_14_2')\n",
    "    print('Train Epoch: {}, Loss: {:.6f}, loss bulk: {:.6f}, loss surf: {:.6f}'.format(j, loss.item(), loss_bulk.item(), loss_surf.item()))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "toc()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "chOq2cxHg6jr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./poisson_equationenergy_24_14_2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u: L2_rel: 0.094188, H1_semi_rel: 0.073567\n",
      "sigma: L2_rel: 1.000882\n",
      "\n",
      "G_rel: 0.000309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mu_err_h1 = torch.zeros(1)\n",
    "sigma_err_h1 = torch.zeros(1)\n",
    "bdd_err = torch.zeros(1)\n",
    "mu_err_l2 = torch.zeros(1)\n",
    "sigma_err_l2 = torch.zeros(1)\n",
    "G_relative = torch.zeros(1)\n",
    "mu_err_semi = torch.zeros(1)\n",
    "\n",
    "test_set =  np.arange(L, R+dx, dx)\n",
    "\n",
    "for point in test_set:\n",
    "\n",
    "    x = torch.tensor([point+ 0.5*dx])\n",
    "    mu, sigma = model(x)\n",
    "    mu_grad, sigma_grad = model.net_grad(x)\n",
    "    loss=model.loss_function_bulk(x)\n",
    "\n",
    "    # esitmate H1 norm error\n",
    "    mu_diff = (mu - u_exact(x))**2  + (mu_grad + sigma_exact(x))**2\n",
    "    mu_diff_simi = (mu_grad + sigma_exact(x))**2\n",
    "    sigma_diff = (sigma - sigma_exact(x))**2 + (sigma_grad - f(x))**2\n",
    "    mu_err_h1 += dx*mu_diff\n",
    "    sigma_err_h1 += dx*sigma_diff\n",
    "    \n",
    "    # estimate L2 norm error\n",
    "    mu_err_l2 += dx*(mu - u_exact(x))**2\n",
    "    sigma_err_l2 += dx*(sigma - sigma_exact(x))**2\n",
    "    \n",
    "    # estimate H1 semi norm  error\n",
    "    #mu_err_semi    = mu_err_h1 - mu_err_l2\n",
    "    mu_err_semi += dx*mu_diff_simi\n",
    "    sigma_err_semi = sigma_err_h1 - sigma_err_l2\n",
    "\n",
    "H1_err = mu_err_h1 + sigma_err_h1  \n",
    "H1_err_relative = ((H1_err)**(1/2)) / ((u_h1 + sigma_h1)**(1/2))\n",
    "L2_err = mu_err_l2 + sigma_err_l2\n",
    "L2_err_relative = ((L2_err)**(1/2)) / ((u_l2 + sigma_l2)**(1/2))\n",
    "mu_err_h1_relative = (mu_err_h1/u_h1)**(1/2)\n",
    "mu_err_l2_relative = (mu_err_l2/u_l2)**(1/2)\n",
    "mu_err_semi_relative = (mu_err_semi/(sigma_l2))**(1/2)\n",
    "sigma_err_h1_relative = (sigma_err_h1/sigma_h1)**(1/2)\n",
    "sigma_err_l2_relative = (sigma_err_l2/sigma_l2)**(1/2)\n",
    "sigma_err_semi_relative = (sigma_err_semi/(sigma_h1 - sigma_l2))**(1/2)\n",
    "bdd_err += abs(mu - g(x))\n",
    "G_rel = (loss)**(1/2)/((u_h1 + sigma_h1)**(1/2))\n",
    "\n",
    "                              \n",
    "print('u: L2_rel: {:.6f}, H1_semi_rel: {:.6f}'.format( mu_err_l2_relative.item(), mu_err_semi_relative.item()))\n",
    "print('sigma: L2_rel: {:.6f}\\n'.format(sigma_err_l2_relative.item()))\n",
    "print('G_rel: {:.6f}\\n'.format(G_rel.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "qbBJ2up3g6jw",
    "outputId": "759eddb5-8da1-4792-9c27-3e7c64844f2a"
   },
   "outputs": [],
   "source": [
    "points = test_set\n",
    "yt = np.zeros_like(points)\n",
    "y_diff = np.zeros_like(points)\n",
    "ymu = np.zeros_like(points)\n",
    "ysig = np.zeros_like(points)\n",
    "for i in range(len(points)):\n",
    "    yt[i] = u_exact(points[i])\n",
    "    y_diff[i] =  -exp(-(points[i]-1/3)**2/0.01)*(-200*points[i]**2 + (200/3)*points[i] + 1)\n",
    "    ymu[i], ysig[i] = model(torch.tensor([points[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "_x8gNI5Kg6jy",
    "outputId": "b4a23f12-9977-4427-b79e-adc2cbd0038b"
   },
   "outputs": [],
   "source": [
    "plt.plot(points, yt, label = 'u_true')\n",
    "plt.plot(points, ymu, label = 'u_approximation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "WfaNso3wg6j1"
   },
   "outputs": [],
   "source": [
    "plt.plot(points, y_diff, label = 'sigma_true')\n",
    "plt.plot(points, ysig, label = 'sigma_approximation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Pd-iKJKrg6j5"
   },
   "outputs": [],
   "source": [
    "num = np.arange(1, len(loss_bulk_record)+1, 1)\n",
    "plt.plot(num, loss_bulk_record)\n",
    "plt.plot(num, loss_surf_record)\n",
    "plt.plot(num, np.add(loss_bulk_record , loss_surf_record))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "Poisson Equation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
